{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#워닝 메시지\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= load_breast_cancer()\n",
    "X_data = data.data\n",
    "y_data = data.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data, test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 개별 모델들\n",
    "svm= SVC()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "lr= LogisticRegression()\n",
    "\n",
    "## 메타 모델\n",
    "lgbm= LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train,y_train)\n",
    "rf.fit(X_train,y_train)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n",
      "0.9649122807017544\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "svm_pred= svm.predict(X_test)\n",
    "rf_pred= rf.predict(X_test)\n",
    "lr_pred= lr.predict(X_test)\n",
    "\n",
    "print(accuracy_score(svm_pred,y_test))\n",
    "print(accuracy_score(rf_pred,y_test))\n",
    "print(accuracy_score(lr_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 114)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([svm_pred,rf_pred,lr_pred])\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data.T\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "lgbm.fit(new_data,y_test)\n",
    "lgbm_pred = lgbm.predict(new_data)\n",
    "print(accuracy_score(y_test, lgbm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    \n",
    "    # 추후 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__,' model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('\\t 폴드 세트: ',folder_counter+1,' 시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "       \n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC  model 시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n",
      "\t 폴드 세트:  6  시작\n",
      "\t 폴드 세트:  7  시작\n",
      "RandomForestClassifier  model 시작\n",
      "\t 폴드 세트:  1  시작\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n",
      "\t 폴드 세트:  6  시작\n",
      "\t 폴드 세트:  7  시작\n",
      "LogisticRegression  model 시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n",
      "\t 폴드 세트:  6  시작\n",
      "\t 폴드 세트:  7  시작\n"
     ]
    }
   ],
   "source": [
    "svm_train, svm_test = get_stacking_base_datasets(svm, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf, X_train, y_train, X_test, 7)\n",
    "lr_train, lr_test = get_stacking_base_datasets(lr, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 shape: (455, 30) 원본 테스트 피처 shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 shape: (455, 3) 스태킹 테스트 피처 데이터 shape: (114, 3)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((svm_train, rf_train, lr_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((svm_test, rf_test, lr_test), axis=1)\n",
    "print('원본 학습 피처 데이터 shape:', X_train.shape, '원본 테스트 피처 shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 shape:',Stack_final_X_train.shape,\n",
    "     '스태킹 테스트 피처 데이터 shape:',Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 메타 모델 -->lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_final= LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도:  0.9736842105263158\n",
      "최종 메타 모델의 예측 f1:  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "lgbm_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lgbm_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: ', accuracy_score(y_test, stack_final))\n",
    "print('최종 메타 모델의 예측 f1: ', f1_score(y_test, stack_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- pipe - line을 이용한 stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 정확도: 0.8462\n",
      "평균 F1 점수: 0.9017\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 데이터를 불러오기\n",
    "data = load_breast_cancer()\n",
    "X_data = data.data\n",
    "y_data = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "# 7-fold 교차 검증을 위한 KFold 객체 생성 (수정)\n",
    "n_splits = 7\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)  # shuffle=True로 수정\n",
    "\n",
    "# 첫 번째 레벨 모델 정의\n",
    "models_first_level = [\n",
    "    ('logreg', LogisticRegression()),\n",
    "    ('svc', SVC()),  # XGBoost(XGB)를 SVC로 변경\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# 메타 모델로 사용할 LightGBM 정의\n",
    "meta_model = LGBMClassifier()\n",
    "\n",
    "# 파이프라인으로 스태킹 모델 생성\n",
    "stacking_model = Pipeline([\n",
    "    # 첫 번째 레벨 모델들을 튜플로 전달하여 스태킹 모델 생성\n",
    "    ('stacked_models', models_first_level),\n",
    "    # 메타 모델로 LightGBM 사용\n",
    "    ('meta_model', meta_model)\n",
    "])\n",
    "\n",
    "# 정확도와 F1 점수를 저장할 리스트 초기화\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# 스태킹에 사용할 빈 배열 생성 (훈련 데이터의 예측 결과를 저장할 것임)\n",
    "X_stacked_train = np.zeros((X_train.shape[0], len(models_first_level)))\n",
    "\n",
    "# 7-kfold 스태킹 수행 (수정)\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 각 모델별로 학습 및 예측 수행하여 트레인 데이터를 예측 결과로 저장\n",
    "    for i, (_, model) in enumerate(models_first_level):\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        X_stacked_train[val_idx, i] = model.predict(X_val_fold)\n",
    "\n",
    "    # 메타 모델 학습\n",
    "    meta_model.fit(X_stacked_train, y_train)\n",
    "    \n",
    "    # 검증 데이터를 사용하여 예측\n",
    "    y_pred = meta_model.predict(X_stacked_train[val_idx])\n",
    "    \n",
    "    # 정확도와 F1 점수 계산하여 리스트에 추가\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    f1 = f1_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# 최종 정확도 및 F1 점수 계산\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "print(f\"평균 정확도: {mean_accuracy:.4f}\")\n",
    "print(f\"평균 F1 점수: {mean_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 훈련 데이터를 여러 개의 모델에 입력으로 주어 1단계 예측을 수행합니다. 이 때, 훈련 데이터를 여러 개의 폴드로 나누어 교차 검증(Cross-validation)을 사용하여 각 모델의 예측 결과를 얻습니다.\n",
    "\n",
    "- 1단계 예측 결과를 모아 새로운 훈련 데이터를 생성합니다. 즉, 각 모델의 예측 결과를 새로운 피처로 사용합니다.\n",
    "\n",
    "- 새로운 훈련 데이터를 이용하여 메타 모델(Meta Model)을 학습시킵니다. 메타 모델은 원본 훈련 데이터의 레이블을 타겟으로 하여 학습합니다.\n",
    "\n",
    "- 테스트 데이터를 1단계 모델에 입력으로 주어 예측 결과를 얻습니다.\n",
    "\n",
    "- 1단계 예측 결과를 새로운 피처로 사용하여 메타 모델을 이용하여 최종 예측을 수행합니다.\n",
    "\n",
    "- 최종 예측 결과를 평가합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제공해주신 코드: 각 모델별로 따로 학습하여 예측한 결과를 사용하여 스태킹을 수행하는 방식입니다. 먼저, 데이터를 여러 개의 폴드로 나누고, 각 폴드에 대해 각 모델을 따로 학습시킵니다. 그런 다음, 각 모델별로 예측한 결과를 저장합니다. 즉, SVM 모델의 예측 결과, 랜덤 포레스트 모델의 예측 결과, 로지스틱 회귀 모델의 예측 결과를 따로 저장합니다. 그리고 이렇게 따로 저장된 모델별 예측 결과들을 합쳐서 하나의 스태킹 모델의 입력 데이터로 사용합니다. 이렇게 합쳐진 입력 데이터로 메타 모델(여기서는 LightGBM)을 학습시킵니다.\n",
    "\n",
    "제가 제공한 파이프라인 코드: 파이프라인을 사용하여 각 모델을 연결하고, 하나의 스태킹 모델로 학습 및 예측을 진행하는 방식입니다. 파이프라인은 여러 단계의 변환(또는 모델 학습)을 연속적으로 적용하고, 마지막 단계의 출력을 사용하여 최종 결과를 만들어냅니다. 이 방법에서는 파이프라인을 사용하여 SVM, 랜덤 포레스트, 로지스틱 회귀 세 모델을 연결하여 하나의 스태킹 모델을 만듭니다. 파이프라인에 학습 데이터를 입력하면, 각 모델이 순차적으로 학습하고 예측 결과를 합쳐서 스태킹 모델에 입력으로 사용합니다. 그리고 이렇게 하나의 스태킹 모델로 학습된 모델을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "두 코드 모두 스태킹 모델을 구성하는 데에 사용될 수 있고, 결과적으로 예측 결과를 얻을 수 있습니다. 다만, 제공해주신 코드는 각 모델별로 따로 예측 결과를 저장하고 합치는 작업을 직접 구현한 것이고, 파이프라인 코드는 사이킷런의 Pipeline을 사용하여 코드를 더 간결하게 구성한 것입니다. 코드를 더 간결하고 관리하기 쉽게 만들어주는 파이프라인 방법을 사용하시면 됩니다. 원하는 방식으로 코드를 선택하여 사용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
